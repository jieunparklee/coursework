{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network Example\n",
    "\n",
    "Build a convolutional neural network with TensorFlow.\n",
    "\n",
    "This example is using TensorFlow layers API, see 'convolutional_network_raw' example\n",
    "for a raw TensorFlow implementation with variables.\n",
    "\n",
    "- Author: Aymeric Damien\n",
    "- Project: https://github.com/aymericdamien/TensorFlow-Examples/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Overview\n",
    "\n",
    "![CNN](http://personal.ie.cuhk.edu.hk/~ccloy/project_target_code/images/fig3.png)\n",
    "\n",
    "## MNIST Dataset Overview\n",
    "\n",
    "This example is using MNIST handwritten digits. The dataset contains 60,000 examples for training and 10,000 examples for testing. The digits have been size-normalized and centered in a fixed-size image (28x28 pixels) with values from 0 to 1. For simplicity, each image has been flatten and converted to a 1-D numpy array of 784 features (28*28).\n",
    "\n",
    "![MNIST Dataset](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png)\n",
    "\n",
    "More info: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 2000\n",
    "batch_size = 128\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 784 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75 # Dropout, probability to keep units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the neural network\n",
    "def conv_net(x_dict, n_classes, dropout, reuse, is_training):\n",
    "    \n",
    "    # Define a scope for reusing the variables\n",
    "    with tf.variable_scope('ConvNet', reuse=reuse):\n",
    "        # TF Estimator input is a dict, in case of multiple inputs\n",
    "        x = x_dict['images']\n",
    "\n",
    "        # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n",
    "        # Reshape to match picture format [Height x Width x Channel]\n",
    "        # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
    "        x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "        # Convolution Layer with 32 filters and a kernel size of 5\n",
    "        conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
    "        conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
    "\n",
    "        # Convolution Layer with 64 filters and a kernel size of 3\n",
    "        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
    "        conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
    "\n",
    "        # Flatten the data to a 1-D vector for the fully connected layer\n",
    "        fc1 = tf.contrib.layers.flatten(conv2)\n",
    "\n",
    "        # Fully connected layer (in tf contrib folder for now)\n",
    "        fc1 = tf.layers.dense(fc1, 1024)\n",
    "        # Apply Dropout (if is_training is False, dropout is not applied)\n",
    "        fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n",
    "\n",
    "        # Output layer, class prediction\n",
    "        out = tf.layers.dense(fc1, n_classes)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the model function (following TF Estimator Template)\n",
    "def model_fn(features, labels, mode):\n",
    "    # Build the neural network\n",
    "    # Because Dropout have different behavior at training and prediction time, we\n",
    "    # need to create 2 distinct computation graphs that still share the same weights.\n",
    "    logits_train = conv_net(features, num_classes, dropout, reuse=False, is_training=True)\n",
    "    logits_test = conv_net(features, num_classes, dropout, reuse=True, is_training=False)\n",
    "    \n",
    "    # Predictions\n",
    "    pred_classes = tf.argmax(logits_test, axis=1)\n",
    "    pred_probas = tf.nn.softmax(logits_test)\n",
    "    \n",
    "    # If prediction mode, early return\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes) \n",
    "        \n",
    "    # Define loss and optimizer\n",
    "    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    # Evaluate the accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "    \n",
    "    # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "    # the different ops for training, evaluating, ...\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=pred_classes,\n",
    "      loss=loss_op,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "    return estim_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/8f/12cv29sj2ml1jk86bghkg2jc0000gn/T/tmptn20izk_\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/8f/12cv29sj2ml1jk86bghkg2jc0000gn/T/tmptn20izk_', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "# Build the Estimator\n",
    "model = tf.estimator.Estimator(model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_fn\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/8f/12cv29sj2ml1jk86bghkg2jc0000gn/T/tmptn20izk_/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.33056, step = 1\n",
      "INFO:tensorflow:global_step/sec: 5.84387\n",
      "INFO:tensorflow:loss = 0.195949, step = 101 (17.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.76409\n",
      "INFO:tensorflow:loss = 0.0459659, step = 201 (17.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.53195\n",
      "INFO:tensorflow:loss = 0.0622511, step = 301 (18.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.62265\n",
      "INFO:tensorflow:loss = 0.12267, step = 401 (15.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.966\n",
      "INFO:tensorflow:loss = 0.0736858, step = 501 (16.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.03138\n",
      "INFO:tensorflow:loss = 0.0410822, step = 601 (16.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.32067\n",
      "INFO:tensorflow:loss = 0.0278764, step = 701 (15.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.7479\n",
      "INFO:tensorflow:loss = 0.0102187, step = 801 (14.818 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.34256\n",
      "INFO:tensorflow:loss = 0.0191954, step = 901 (15.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.5889\n",
      "INFO:tensorflow:loss = 0.0163567, step = 1001 (17.893 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.87781\n",
      "INFO:tensorflow:loss = 0.0100845, step = 1101 (17.013 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.94866\n",
      "INFO:tensorflow:loss = 0.0482287, step = 1201 (16.810 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.7081\n",
      "INFO:tensorflow:loss = 0.0642444, step = 1301 (17.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.70044\n",
      "INFO:tensorflow:loss = 0.0404148, step = 1401 (14.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.73904\n",
      "INFO:tensorflow:loss = 0.0143561, step = 1501 (14.840 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.27023\n",
      "INFO:tensorflow:loss = 0.0297491, step = 1601 (15.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.71676\n",
      "INFO:tensorflow:loss = 0.0129082, step = 1701 (14.888 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.25244\n",
      "INFO:tensorflow:loss = 0.0288308, step = 1801 (19.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.07209\n",
      "INFO:tensorflow:loss = 0.0440722, step = 1901 (16.469 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /var/folders/8f/12cv29sj2ml1jk86bghkg2jc0000gn/T/tmptn20izk_/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00970279.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x126cb8a20>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the input function for training\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': mnist.train.images}, y=mnist.train.labels,\n",
    "    batch_size=batch_size, num_epochs=None, shuffle=True)\n",
    "# Train the Model\n",
    "model.train(input_fn, steps=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_fn\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-25-17:13:22\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/8f/12cv29sj2ml1jk86bghkg2jc0000gn/T/tmptn20izk_/model.ckpt-2000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-25-17:13:26\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.9883, global_step = 2000, loss = 0.0507867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.98830003, 'global_step': 2000, 'loss': 0.050786663}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "# Define the input function for evaluating\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': mnist.test.images}, y=mnist.test.labels,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "model.evaluate(input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/8f/12cv29sj2ml1jk86bghkg2jc0000gn/T/tmp9k3jb36r/model.ckpt-2000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADPBJREFUeJzt3V2IXfW5x/Hf76QpiOlFYjUMNpoKerCKTHQUwViiHktO\nLMRikHpxyIGS6UVOaKGEiufi5LJIX6g3gSkNjYccWyGtRhGPGg/mBLU4ETWJMTEJqZmYtzJCE0Ha\n6NOLWbbTOPu/d/bb2uPz/cAwe69nvTxs5jdrrb322n9HhADk8091NwCgHoQfSIrwA0kRfiApwg8k\nRfiBpAg/kBThB5Ii/EBSX+jnxmzzcUKgxyLCrczX0Z7f9nLb+20ftP1gJ+sC0F9u97P9tudIOiDp\nbkkTkl6T9EBEvF1Yhj0/0GP92PPfIulgRByOiD9L+rWklR2sD0AfdRL+yyUdnfZ8opr2D2yP2h63\nPd7BtgB0Wc/f8IuIMUljEof9wCDpZM9/TNKiac+/Uk0DMAt0Ev7XJF1t+6u2vyjp25K2dactAL3W\n9mF/RJyz/R+S/lfSHEmbImJv1zoD0FNtX+pra2Oc8wM915cP+QCYvQg/kBThB5Ii/EBShB9IivAD\nSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrw\nA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9Iqu0huiXJ9hFJZyR9LOlcRIx0oykAvddR+Ct3RMQf\nu7AeAH3EYT+QVKfhD0kv2N5le7QbDQHoj04P+5dGxDHbl0l63vY7EbFj+gzVPwX+MQADxhHRnRXZ\nGySdjYgfF+bpzsYANBQRbmW+tg/7bV9s+0ufPpb0DUl72l0fgP7q5LB/oaTf2f50Pf8TEc92pSsA\nPde1w/6WNsZhP9BzPT/sBzC7EX4gKcIPJEX4gaQIP5AU4QeS6sZdfSmsWrWqYW3NmjXFZd9///1i\n/aOPPirWt2zZUqyfOHGiYe3gwYPFZZEXe34gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIpbelt0+PDh\nhrXFixf3r5EZnDlzpmFt7969fexksExMTDSsPfzww8Vlx8fHu91O33BLL4Aiwg8kRfiBpAg/kBTh\nB5Ii/EBShB9Iivv5W1S6Z/+GG24oLrtv375i/dprry3Wb7zxxmJ92bJlDWu33nprcdmjR48W64sW\nLSrWO3Hu3Lli/fTp08X60NBQ29t+7733ivXZfJ2/Vez5gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiCp\npvfz294k6ZuSTkXE9dW0BZJ+I2mxpCOS7o+ID5pubBbfzz/I5s+f37A2PDxcXHbXrl3F+s0339xW\nT61oNl7BgQMHivVmn59YsGBBw9ratWuLy27cuLFYH2TdvJ//V5KWnzftQUnbI+JqSdur5wBmkabh\nj4gdkibPm7xS0ubq8WZJ93a5LwA91u45/8KIOF49PiFpYZf6AdAnHX+2PyKidC5ve1TSaKfbAdBd\n7e75T9oekqTq96lGM0bEWESMRMRIm9sC0APthn+bpNXV49WSnuxOOwD6pWn4bT8m6RVJ/2x7wvZ3\nJP1I0t2235X0L9VzALMI39uPgXXfffcV648//nixvmfPnoa1O+64o7js5OT5F7hmD763H0AR4QeS\nIvxAUoQfSIrwA0kRfiApLvWhNpdddlmxvnv37o6WX7VqVcPa1q1bi8vOZlzqA1BE+IGkCD+QFOEH\nkiL8QFKEH0iK8ANJMUQ3atPs67MvvfTSYv2DD8rfFr9///4L7ikT9vxAUoQfSIrwA0kRfiApwg8k\nRfiBpAg/kBT386Onbrvttoa1F198sbjs3Llzi/Vly5YV6zt27CjWP6+4nx9AEeEHkiL8QFKEH0iK\n8ANJEX4gKcIPJNX0fn7bmyR9U9KpiLi+mrZB0hpJp6vZHoqIZ3rVJGavFStWNKw1u46/ffv2Yv2V\nV15pqydMaWXP/ytJy2eY/rOIGK5+CD4wyzQNf0TskDTZh14A9FEn5/zrbL9le5Pt+V3rCEBftBv+\njZKukjQs6biknzSa0fao7XHb421uC0APtBX+iDgZER9HxCeSfiHplsK8YxExEhEj7TYJoPvaCr/t\noWlPvyVpT3faAdAvrVzqe0zSMklftj0h6b8kLbM9LCkkHZH03R72CKAHuJ8fHbnooouK9Z07dzas\nXXfddcVl77zzzmL95ZdfLtaz4n5+AEWEH0iK8ANJEX4gKcIPJEX4gaQYohsdWb9+fbG+ZMmShrVn\nn322uCyX8nqLPT+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJMUtvSi65557ivUnnniiWP/www8b1pYv\nn+lLof/u1VdfLdYxM27pBVBE+IGkCD+QFOEHkiL8QFKEH0iK8ANJcT9/cpdcckmx/sgjjxTrc+bM\nKdafeabxAM5cx68Xe34gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSKrp/fy2F0l6VNJCSSFpLCJ+bnuB\npN9IWizpiKT7I+KDJuvifv4+a3Ydvtm19ptuuqlYP3ToULFeume/2bJoTzfv5z8n6QcR8TVJt0pa\na/trkh6UtD0irpa0vXoOYJZoGv6IOB4Rr1ePz0jaJ+lySSslba5m2yzp3l41CaD7Luic3/ZiSUsk\n/V7Swog4XpVOaOq0AMAs0fJn+23Pk7RV0vcj4k/2308rIiIanc/bHpU02mmjALqrpT2/7bmaCv6W\niPhtNfmk7aGqPiTp1EzLRsRYRIxExEg3GgbQHU3D76ld/C8l7YuIn04rbZO0unq8WtKT3W8PQK+0\ncqlvqaT/l7Rb0ifV5Ic0dd7/uKQrJP1BU5f6Jpusi0t9fXbNNdcU6++8805H61+5cmWx/tRTT3W0\nfly4Vi/1NT3nj4idkhqt7K4LaQrA4OATfkBShB9IivADSRF+ICnCDyRF+IGk+Oruz4Err7yyYe25\n557raN3r168v1p9++umO1o/6sOcHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaS4zv85MDra+FvSrrji\nio7W/dJLLxXrzb4PAoOLPT+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJMV1/llg6dKlxfq6dev61Ak+\nT9jzA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBSTa/z214k6VFJCyWFpLGI+LntDZLWSDpdzfpQRDzT\nq0Yzu/3224v1efPmtb3uQ4cOFetnz55te90YbK18yOecpB9ExOu2vyRpl+3nq9rPIuLHvWsPQK80\nDX9EHJd0vHp8xvY+SZf3ujEAvXVB5/y2F0taIun31aR1tt+yvcn2/AbLjNoetz3eUacAuqrl8Nue\nJ2mrpO9HxJ8kbZR0laRhTR0Z/GSm5SJiLCJGImKkC/0C6JKWwm97rqaCvyUifitJEXEyIj6OiE8k\n/ULSLb1rE0C3NQ2/bUv6paR9EfHTadOHps32LUl7ut8egF5p5d3+2yT9m6Tdtt+opj0k6QHbw5q6\n/HdE0nd70iE68uabbxbrd911V7E+OTnZzXYwQFp5t3+nJM9Q4po+MIvxCT8gKcIPJEX4gaQIP5AU\n4QeSIvxAUu7nEMu2Gc8Z6LGImOnS/Gew5weSIvxAUoQfSIrwA0kRfiApwg8kRfiBpPo9RPcfJf1h\n2vMvV9MG0aD2Nqh9SfTWrm72dmWrM/b1Qz6f2bg9Pqjf7TeovQ1qXxK9tauu3jjsB5Ii/EBSdYd/\nrObtlwxqb4Pal0Rv7aqlt1rP+QHUp+49P4Ca1BJ+28tt77d90PaDdfTQiO0jtnfbfqPuIcaqYdBO\n2d4zbdoC28/bfrf6PeMwaTX1tsH2seq1e8P2ipp6W2T7/2y/bXuv7e9V02t97Qp91fK69f2w3/Yc\nSQck3S1pQtJrkh6IiLf72kgDto9IGomI2q8J2/66pLOSHo2I66tpD0uajIgfVf8450fEDwektw2S\nztY9cnM1oMzQ9JGlJd0r6d9V42tX6Ot+1fC61bHnv0XSwYg4HBF/lvRrSStr6GPgRcQOSeePmrFS\n0ubq8WZN/fH0XYPeBkJEHI+I16vHZyR9OrJ0ra9doa9a1BH+yyUdnfZ8QoM15HdIesH2LtujdTcz\ng4XVsOmSdELSwjqbmUHTkZv76byRpQfmtWtnxOtu4w2/z1oaEcOS/lXS2urwdiDF1DnbIF2uaWnk\n5n6ZYWTpv6nztWt3xOtuqyP8xyQtmvb8K9W0gRARx6rfpyT9ToM3+vDJTwdJrX6fqrmfvxmkkZtn\nGllaA/DaDdKI13WE/zVJV9v+qu0vSvq2pG019PEZti+u3oiR7YslfUODN/rwNkmrq8erJT1ZYy//\nYFBGbm40srRqfu0GbsTriOj7j6QVmnrH/5Ck/6yjhwZ9XSXpzepnb929SXpMU4eBf9HUeyPfkXSJ\npO2S3pX0gqQFA9Tbf0vaLektTQVtqKbelmrqkP4tSW9UPyvqfu0KfdXyuvEJPyAp3vADkiL8QFKE\nH0iK8ANJEX4gKcIPJEX4gaQIP5DUXwFGhz+pWT5yuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12a341dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12a6f7be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12a5511d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12a6f7940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: 0\n"
     ]
    }
   ],
   "source": [
    "# Predict single images\n",
    "n_images = 4\n",
    "# Get images from test set\n",
    "test_images = mnist.test.images[:n_images]\n",
    "# Prepare the input data\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': test_images}, shuffle=False)\n",
    "# Use the model to predict the images class\n",
    "preds = list(model.predict(input_fn))\n",
    "\n",
    "# Display\n",
    "for i in range(n_images):\n",
    "    plt.imshow(np.reshape(test_images[i], [28, 28]), cmap='gray')\n",
    "    plt.show()\n",
    "    print(\"Model prediction:\", preds[i])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
